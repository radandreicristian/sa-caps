# (Work in Progress) Joint Intent Detection and Slot Labeling via Self-Attention Capsule Networks

1) Capsule Theory

* (Hinton, 2012)
  - [Transforming Auto-Encoders](http://www.cs.toronto.edu/~bonner/courses/2020s/csc2547/papers/capsules/transforming-autoencoders,-hinton,-icann-2011.pdf)
* (Sabour, 2015)
  - [Dynamic Routing Between Capsules](https://papers.nips.cc/paper/2017/file/2cad8fa47bbef282badbb8de5374b894-Paper.pdf)
* (Hahn, 2019)
  - [Self-Routing Capsule Networks](https://papers.nips.cc/paper/2019/file/e46bc064f8e92ac2c404b9871b2a4ef2-Paper.pdf)

2) CapsNets in ID-SF

* (Zhang, 2019)
  - [Joint Slot Filling and Intent Detection via Capsule Neural Networks](https://arxiv.org/pdf/1812.09471.pdf)
* (Xia, 2019) - [Zero-shot User Intent Detection via Capsule Neural Networks](https://arxiv.org/pdf/1809.00385.pdf)
* (Stoica, 2020)
  - [Intent Detection and Slot Filling with Capsule Net Architectures for a Romanian Home Assistant](https://www.mdpi.com/1424-8220/21/4/1230/pdf)

3) Transformers / Self-Attention

* (Vaswani, 2016)
  - [Attention is all you need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
* (Devlin, 2018)
  - [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)
* (Bunk, 2020) - [DIET: Lightweight Language Understanding for Dialogue Systems](https://arxiv.org/pdf/2004.09936.pdf)

4) Transformer-Capsule Architectures

* (Duan, 2020) - [Capsule-Transformer for Neural Machine Translation](https://arxiv.org/pdf/2004.14649)
* (Obuchowski, 2020)
  - [Transformer-Capsule Model for Intent Detection](https://www.aaai.org/ojs/index.php/AAAI/article/view/7215/7069)
* (Mobiny, 2020)
  - [Trans-Caps: Transformer Capslue Networks with Self-Attention Routing](https://openreview.net/pdf?id=BUPIRa1D2J)

5) Word Embeddings


6) Others

* (Defazio, 2021)
  - [Adaptivity without Compromise: A Momentumized, Adaptive, Dual Averaged Gradiewnt Method for Stochastic Optimization](https://arxiv.org/pdf/2101.11075.pdf)

https://github.com/Botfuel/benchmark-nlp-2018